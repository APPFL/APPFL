train_configs:
  client_idx: 0
  num_clients: 2
  trainer: FedSBTrainer
  agg_type: fed-sb
  seed: 42
  lora_r: 200
  lora_alpha: 200
  eg_bs: 3
  batch_size: 1
  scheduler: cosine
  warmup_ratio: 0.02
  num_samples: 50
  epochs: 1
  run_dir: experiments/instruction_tuning
  model: meta-llama/Llama-3.2-3B
  data_path: meta-math/MetaMathQA
  dataset_field: ["query", "response"]
  dataset_split: "train[:20000]"
  wandb_configs:
    enable_wandb: True
    entity: zl52-university-of-illinois-urbana-champaign
    project: appfl
    exp_name: fed-sb-arithmetic-2
    max_seq_length: 512
  reconstruction_configs:
    reconstruction_type: "svd"
    reconstr_mode: "separated"
    half_init_dec: False
    replacement_module_random_init: False
    r_squared: True
    svd:
      n_iter: 10
      random_state: 42