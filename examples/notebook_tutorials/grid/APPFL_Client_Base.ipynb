{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "## Federated learning using APPFL\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/APPFL/APPFL/blob/main/docs/_static/logo/logo_small.png?raw=true\" width=\"40%\" alt=\"APPFL Logo\">\n",
    "\n",
    "\n",
    "In this tutorial, we will leverage the Advanced Privacy-Preserving Federated Learning ([APPFL](https://github.com/APPFL/APPFL)) framework to launch a federated learning client for running a federated learning experiment with two clients and one central server. The server launching code is available in your workspace as **APPFL_Server.ipynb**. Please make sure you first launch the server before launching this client.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this example, we will be working on the gridfm graphkit dataset. **This notebook represents the Client 1.**\n",
    "\n",
    "### Training Settings\n",
    "\n",
    "We use a gridfm graphkit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WARNING]: Please only run this cell ONCE at the beginning of your script.\n",
    "# First: Change the working directory to the root of the repository and ignore warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_value = 1\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkDy4V_K-QJJ"
   },
   "source": [
    "### 1. Create federated learning client agent from configurations\n",
    "\n",
    "We need to update the `server_uri` to the URL obtained from the **server** notebook.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "- ##### Obtain the `server` URL:\n",
    "  - For example, the server URL from the server notebook is `172.31.79.131:50051`.\n",
    "\n",
    "- ##### Update the code:\n",
    "  - Replace the placeholder in the following line with the actual `server` URL obtained.\n",
    "\n",
    "  - Update the code as follows:\n",
    "`client_agent_config.comm_configs.grpc_configs[\"server_uri\"] = \"172.31.79.131:50051\"`\n",
    "\n",
    "In the client configurations, it has four main parts:\n",
    "\n",
    "- `client_id`: A unique identifier for the client\n",
    "- `train_configs`: Client-specific training related configurations, such as the device and logging directories\n",
    "- `data_configs`: Information about the dataloader file that can create a PyTorch dataset for the IXI data\n",
    "- `comm_configs`: Information needed to connect to the server notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = \n",
    "CLIENT_ID = \n",
    "SERVER_URI = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYtswTpp-RZB",
    "outputId": "5083902b-a945-4690-a7f7-2461f006e70d"
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from appfl.agent import ClientAgent\n",
    "\n",
    "client_agent_config = OmegaConf.load(\n",
    "    \"./resources/configs/grid/client_1.yaml\"\n",
    ")\n",
    "client_agent_config.comm_configs.grpc_configs[\"server_uri\"] = (\n",
    "    str(SERVER_URI)  # Reminder: Replace this with the URI you got from the server notebook!\n",
    ")\n",
    "client_agent_config.client_id = f\"Client{CLIENT_ID}\"\n",
    "client_agent_config.data_configs.dataset_kwargs[\"num_clients\"] = NUM_CLIENTS\n",
    "client_agent_config.data_configs.dataset_kwargs[\"client_id\"] = CLIENT_ID - 1\n",
    "\n",
    "print(\"==========Client Configuration==========\")\n",
    "print(OmegaConf.to_yaml(client_agent_config))\n",
    "print(\"========================================\")\n",
    "client_agent = ClientAgent(client_agent_config=client_agent_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN8wjKKi-djv"
   },
   "source": [
    "### 2. Create Client Communicator\n",
    "\n",
    "Now, we create a grpc client communicator for sending various requests to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBTwkiaN-c_y",
    "outputId": "daf4f2fa-4113-48e0-a56c-e73562fa0f4b"
   },
   "outputs": [],
   "source": [
    "from appfl.comm.grpc import GRPCClientCommunicator\n",
    "\n",
    "client_communicator = GRPCClientCommunicator(\n",
    "    client_id=client_agent.get_id(),\n",
    "    **client_agent_config.comm_configs.grpc_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start training loop by sending requests to server.\n",
    "\n",
    "In this main training loop, it has four main types of request to send to the server:\n",
    "\n",
    "(1) `get_configuration()`: Get general client configurations for local training\n",
    "\n",
    "(2) `get_global_model(init_model=True)`: Get the initial global model for training\n",
    "\n",
    "(3) `update_global_model()`: Send the trained local model to update the global model, and get the updated model back for further local training\n",
    "\n",
    "(4) `invoke_custom_action(action=\"close_connection\")`: Close the connection with the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get general client configurations\n",
    "client_config = client_communicator.get_configuration()\n",
    "client_agent.load_config(client_config)\n",
    "\n",
    "# Get initial global model parameters\n",
    "init_global_model = client_communicator.get_global_model(init_model=True)\n",
    "client_agent.load_parameters(init_global_model)\n",
    "\n",
    "# Start local training loop\n",
    "while True:\n",
    "    client_agent.train()\n",
    "    local_model, metadata = client_agent.get_parameters()\n",
    "    new_global_model, metadata = client_communicator.update_global_model(\n",
    "        local_model, **metadata\n",
    "    )\n",
    "    if metadata[\"status\"] == \"DONE\":\n",
    "        break\n",
    "    client_agent.load_parameters(new_global_model)\n",
    "\n",
    "# Close connection\n",
    "client_communicator.invoke_custom_action(action=\"close_connection\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "appfl-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
