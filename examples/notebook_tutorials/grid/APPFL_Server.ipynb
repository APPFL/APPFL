{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5eBqr9EcfY5"
   },
   "source": [
    "## Federated Learning Tutorial: Launching the Server\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/APPFL/APPFL/blob/main/docs/_static/logo/logo_small.png?raw=true\" width=\"40%\" alt=\"APPFL Logo\">\n",
    "\n",
    "\n",
    "In this tutorial, we will leverage the Advanced Privacy-Preserving Federated Learning ([APPFL](https://github.com/APPFL/APPFL)) framework to launch a federated learning server for orchestrating federated learning experiments between two distributed clients, whose client-launching code are available in your jupyter workspace as **Client1 (APPFL_Client1.ipynb)** and **Client2 (APPFL_Client2.ipynb)**.\n",
    "\n",
    "This example will train a model from the gridfm graphkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sef5e_7iceAI"
   },
   "source": [
    "### 1. Create federated learning server agent from configurations\n",
    "\n",
    "Here we print the configurations needed to create a federated learning server. Specifically, it is composed of two main parts: `client_configs` and `server_configs`.\n",
    "\n",
    "The `client_configs` mainly contains **general** configurations that should be the same among all clients (e.g., training configurations, model architectures). Those configurations will be shared will all the clients at the beginning of experiments. This can avoid having each client to set the same configurations themselves separately. In this example, `client_configs` has two main components:\n",
    "\n",
    "- `client_configs.train_configs`: This component contains configurations related to client's local training, such as the trainer to use, loss function, validation function, etc.\n",
    "\n",
    "- `client_configs.model_configs`: This provides the path which defines the python function to load the architecture of the model to be trained.\n",
    "\n",
    "\n",
    "The `server_configs` contains configurations that are specific to the federated learning server, such as the number of global epochs (total communication rounds between server and clients), and aggregators to use, etc.\n",
    "\n",
    "\n",
    " If you are interested, you can find more detailed explanations for the meanings of different configuration fields at [APPFL's official document](https://appfl.ai/en/latest/users/server_agent.html#configurations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WARNING]: Please only run this cell ONCE at the beginning of your script.\n",
    "# First: Change the working directory to the root of the repository and ignore warnings\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_value = 1\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENT = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NmWCRCp0zG1",
    "outputId": "526a5d29-776d-4b7d-d688-e6cc6a1b52e1"
   },
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from appfl.agent import ServerAgent\n",
    "\n",
    "server_agent_config = OmegaConf.load(\n",
    "    \"./resources/configs/grid/server_fedavg.yaml\"\n",
    ")\n",
    "\n",
    "server_agent_config.server_configs[\"num_clients\"] = NUM_CLIENT  # Set the number of clients\n",
    "\n",
    "print(\"==========Server Configuration==========\")\n",
    "print(OmegaConf.to_yaml(server_agent_config))\n",
    "print(\"========================================\")\n",
    "server_agent = ServerAgent(server_agent_config=server_agent_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gRPC server communicator creation\n",
    "\n",
    "In this step, we create a server communicator that facilitates communication between the server and its clients using gRPC. It provides a reliable medium for the server and clients to exchange information efficiently and asynchronously.\n",
    "\n",
    "**The following code block will print out a link that you need to copy to your two client notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from appfl.comm.grpc import GRPCServerCommunicator\n",
    "\n",
    "# Start the gRPC server communicator\n",
    "communicator = GRPCServerCommunicator(\n",
    "    server_agent,\n",
    "    logger=server_agent.logger,\n",
    "    **server_agent_config.server_configs.comm_configs.grpc_configs,\n",
    ")\n",
    "\n",
    "# Getting the private IP address of the server\n",
    "hostname = socket.gethostname()\n",
    "private_ip = socket.gethostbyname(hostname)\n",
    "print(f\"\\n\\nâœ… Replace server_uri with below in client notebook: {private_ip}:50051\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Launch the Server\n",
    "\n",
    "Finally, you can use the communicator to start serving the FL server, which will handle different requests from the two clients to finish the FL experiments.\n",
    "\n",
    "The client training results are logged in real time as a dictionary containing metrics such as `pre_val_accuracy` and `pre_val_loss` (accuracy and loss before each client's local training round) and `val_accuracy` and `val_loss` (accuracy and loss afterward). You will observe an increase in the model accuracy as the training proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appfl.comm.grpc import serve\n",
    "\n",
    "serve(\n",
    "    communicator,\n",
    "    **server_agent_config.server_configs.comm_configs.grpc_configs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MyEnvironment",
   "language": "python",
   "name": "appfl-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
