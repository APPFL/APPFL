client_configs:
  train_configs:
    trainer: "LLMDummyTrainer"

  model_configs:
    model_path: "./resources/model/hf_llm.py"
    model_name: "load_hf_llm"
    model_kwargs:
      model_name: "meta-llama/Llama-3.2-1B"

server_configs:
  num_clients: 2
  scheduler: "SyncScheduler"
  scheduler_kwargs:
    same_init_model: True
  aggregator: "FedAvgAggregator"
  aggregator_kwargs:
    client_weights_mode: "equal"
  device: "cpu"
  num_global_epochs: 5  # Reduced for faster profiling
  logging_output_dirname: "./output"
  logging_output_filename: "result"
  comm_configs:
    grpc_configs:
      server_uri: localhost:50051
      max_message_size: 10485760  # 10MB for ResNet parameters
      use_ssl: False
