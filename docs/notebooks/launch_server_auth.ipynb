{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch gRPC server with Authentication\n",
    "\n",
    "In this notebook, we will present how to launch a gRPC server as a federated learning server with authentication. Consider only one client so that we can launch a server and a client (from another notebook) together.\n",
    "\n",
    "The following figure illustrates the gRPC communication with token-based authenticator.\n",
    "\n",
    "First, as there are tokens transfered from clients to server for authentication, it is required to use **secure SSL channel** for gRPC communication to encrypte the transmitted data. In each RPC from client to server, the client will attach its authentication token as call metadata and send to the server for validation. `APPFL` currently supports two types of authenticators [`NaiveAuthenticator`](../../src/appfl/login_manager/naive/naive_authenticator.py) for demonstration purposes and [`GlobusAuthenticator`](../../src/appfl/login_manager/globus/globus_authenticator.py) for real deployment. Please refer to the [authenticator documentation](../../src/appfl/login_manager/ReadME.md) to learn more about the authenticators and how to define your own authenticator if needed. \n",
    "\n",
    "In this example, we will use the `NaiveAuthenticator` for easy demonstration, which the client simply uses hardcoded authentication tokens for validation.\n",
    "\n",
    "<img src=\"../../docs/_static/grpc_auth.jpg\" alt=\"GRPC Auth\" title=\"GRPC Auth\" width=\"50%\" height=\"auto\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "We put all the imports here. \n",
    "Our framework `appfl` is backboned by `torch` and its neural network model `torch.nn`. We also import `torchvision` to download the `MNIST` dataset.\n",
    "More importantly, we need to import `appfl.run_grpc_server` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from appfl.config import Config\n",
    "from appfl.misc.data import Dataset\n",
    "import appfl.run_grpc_server as grpc_server\n",
    "from omegaconf import OmegaConf, DictConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset\n",
    "\n",
    "The server can also hold test data to check the performance of the global model, and the test data needs to be wrapped in `Dataset` object. Note that the server does not need any training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = torchvision.datasets.MNIST(\n",
    "    \"./_data\", train=False, download=False, transform=ToTensor()\n",
    ")\n",
    "test_data_input = []\n",
    "test_data_label = []\n",
    "for idx in range(len(test_data_raw)):\n",
    "    test_data_input.append(test_data_raw[idx][0].tolist())\n",
    "    test_data_label.append(test_data_raw[idx][1])\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    torch.FloatTensor(test_data_input), torch.tensor(test_data_label)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined model\n",
    "\n",
    "Users can define their own models by deriving `torch.nn.Module`. For example in this simulation, we define the following convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_channel=1, num_classes=10, num_pixel=28):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_channel, 32, kernel_size=5, padding=0, stride=1, bias=True\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=0, stride=1, bias=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "        X = num_pixel\n",
    "        X = math.floor(1 + (X + 2 * 0 - 1 * (5 - 1) - 1) / 1)\n",
    "        X = X / 2\n",
    "        X = math.floor(1 + (X + 2 * 0 - 1 * (5 - 1) - 1) / 1)\n",
    "        X = X / 2\n",
    "        X = int(X)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * X * X, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined loss and metric\n",
    "We define the loss function and the validation metric for the training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()   \n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''\n",
    "    y_true and y_pred are both of type np.ndarray\n",
    "    y_true (N, d) where N is the size of the validation set, and d is the dimension of the label\n",
    "    y_pred (N, D) where N is the size of the validation set, and D is the output dimension of the ML model\n",
    "    '''\n",
    "    if len(y_pred.shape) == 1:\n",
    "        y_pred = np.round(y_pred)\n",
    "    else:\n",
    "        y_pred = y_pred.argmax(axis=1)\n",
    "    return 100*np.sum(y_pred==y_true)/y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configurations\n",
    "\n",
    "We run the `appfl` training with the data and model defined above. \n",
    "A number of parameters can be easily set by changing the configuration values.\n",
    "We read the default configurations from `appfl.config.Config` class as a `DictConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fed:\n",
      "  type: federated\n",
      "  servername: ServerFedAvg\n",
      "  clientname: ClientOptim\n",
      "  args:\n",
      "    server_learning_rate: 0.01\n",
      "    server_adapt_param: 0.001\n",
      "    server_momentum_param_1: 0.9\n",
      "    server_momentum_param_2: 0.99\n",
      "    optim: SGD\n",
      "    num_local_epochs: 10\n",
      "    optim_args:\n",
      "      lr: 0.001\n",
      "    use_dp: false\n",
      "    epsilon: 1\n",
      "    clip_grad: false\n",
      "    clip_value: 1\n",
      "    clip_norm: 1\n",
      "device: cpu\n",
      "device_server: cpu\n",
      "num_clients: 1\n",
      "num_epochs: 2\n",
      "num_workers: 0\n",
      "batch_training: true\n",
      "train_data_batch_size: 64\n",
      "train_data_shuffle: true\n",
      "validation: true\n",
      "test_data_batch_size: 64\n",
      "test_data_shuffle: false\n",
      "data_sanity: false\n",
      "reproduce: true\n",
      "pca_dir: ''\n",
      "params_start: 0\n",
      "params_end: 49\n",
      "ncomponents: 40\n",
      "use_tensorboard: false\n",
      "load_model: false\n",
      "load_model_dirname: ''\n",
      "load_model_filename: ''\n",
      "save_model: false\n",
      "save_model_dirname: ''\n",
      "save_model_filename: ''\n",
      "checkpoints_interval: 2\n",
      "save_model_state_dict: false\n",
      "send_final_model: false\n",
      "output_dirname: output\n",
      "output_filename: result\n",
      "logginginfo: {}\n",
      "summary_file: ''\n",
      "personalization: false\n",
      "p_layers: []\n",
      "config_name: ''\n",
      "max_message_size: 10485760\n",
      "use_ssl: false\n",
      "use_authenticator: false\n",
      "authenticator: Globus\n",
      "uri: localhost:50051\n",
      "operator:\n",
      "  id: 1\n",
      "server:\n",
      "  id: 1\n",
      "  authenticator_kwargs:\n",
      "    is_fl_server: true\n",
      "    globus_group_id: 77c1c74b-a33b-11ed-8951-7b5a369c0a53\n",
      "  server_certificate_key: default\n",
      "  server_certificate: default\n",
      "  max_workers: 10\n",
      "client:\n",
      "  id: 1\n",
      "  root_certificates: default\n",
      "  authenticator_kwargs:\n",
      "    is_fl_server: false\n",
      "enable_compression: false\n",
      "lossy_compressor: SZ2\n",
      "lossless_compressor: blosc\n",
      "compressor_sz2_path: ../.compressor/SZ/build/sz/libSZ.dylib\n",
      "compressor_sz3_path: ../.compressor/SZ3/build/tools/sz3c/libSZ3c.dylib\n",
      "compressor_szx_path: ../.compressor/SZx-main/build/lib/libSZx.dylib\n",
      "error_bounding_mode: ''\n",
      "error_bound: 0.0\n",
      "flat_model_dtype: np.float32\n",
      "param_cutoff: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg: DictConfig = OmegaConf.structured(Config)\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL server and authenticator\n",
    "Secure SSL server requires the server to have a public SSL certificate and a private SSL certificate key for data encryption. We have provided a example pair of [certificate](../../src/appfl/comm/grpc/credentials/localhost.crt) and [key](../../src/appfl/comm/grpc/credentials/localhost.key) for demonstration. **It should be noted that in practice, you should never share your key to others and keep it secretly**. To use the provided certificate and key, just set `cfg.server.server_certificate=\"default\"` and  `cfg.server.server_certificate_key=\"default\"`. If the user would like to use his own certificate and key, just change the corresponding field to the file path.\n",
    "\n",
    "Then to use the `NaiveAuthenticator`, user needs to set `cfg.client.authenticator=\"Naive\"`, and set `cfg.client.authenticator_kwargs={}` as the `NaiveAuthenticator` does not take any argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.server.server_certificate=\"default\"\n",
    "cfg.server.server_certificate_key=\"default\"\n",
    "cfg.server.authenticator=\"Naive\"\n",
    "cfg.server.authenticator_kwargs={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with configurations\n",
    "For the server, we just run it by setting the number of global epochs to 5, and start the **secure** FL experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Round:  001] Finished; all clients have sent their results.\n",
      "[Round:  001] Finished; all clients have sent their results.\n",
      "[Round:  001] Updating model weights\n",
      "[Round:  001] Updating model weights\n",
      "[Round:  001] Test set: Average loss: 0.3082, Accuracy: 90.95%, Best Accuracy: 90.95%\n",
      "[Round:  001] Test set: Average loss: 0.3082, Accuracy: 90.95%, Best Accuracy: 90.95%\n",
      "[Round:  002] Finished; all clients have sent their results.\n",
      "[Round:  002] Finished; all clients have sent their results.\n",
      "[Round:  002] Updating model weights\n",
      "[Round:  002] Updating model weights\n",
      "[Round:  002] Test set: Average loss: 0.1699, Accuracy: 94.94%, Best Accuracy: 94.94%\n",
      "[Round:  002] Test set: Average loss: 0.1699, Accuracy: 94.94%, Best Accuracy: 94.94%\n",
      "[Round:  003] Finished; all clients have sent their results.\n",
      "[Round:  003] Finished; all clients have sent their results.\n",
      "[Round:  003] Updating model weights\n",
      "[Round:  003] Updating model weights\n",
      "[Round:  003] Test set: Average loss: 0.1106, Accuracy: 96.73%, Best Accuracy: 96.73%\n",
      "[Round:  003] Test set: Average loss: 0.1106, Accuracy: 96.73%, Best Accuracy: 96.73%\n",
      "[Round:  004] Finished; all clients have sent their results.\n",
      "[Round:  004] Finished; all clients have sent their results.\n",
      "[Round:  004] Updating model weights\n",
      "[Round:  004] Updating model weights\n",
      "[Round:  004] Test set: Average loss: 0.0852, Accuracy: 97.58%, Best Accuracy: 97.58%\n",
      "[Round:  004] Test set: Average loss: 0.0852, Accuracy: 97.58%, Best Accuracy: 97.58%\n",
      "[Round:  005] Finished; all clients have sent their results.\n",
      "[Round:  005] Finished; all clients have sent their results.\n",
      "[Round:  005] Updating model weights\n",
      "[Round:  005] Updating model weights\n",
      "[Round:  005] Test set: Average loss: 0.0764, Accuracy: 97.77%, Best Accuracy: 97.77%\n",
      "[Round:  005] Test set: Average loss: 0.0764, Accuracy: 97.77%, Best Accuracy: 97.77%\n"
     ]
    }
   ],
   "source": [
    "cfg.num_epochs = 5\n",
    "grpc_server.run_server(cfg, model, loss_fn, num_clients, test_dataset, accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a3775820edfef7d27663833b7a57b274657051daef716a62aaac9a7002010d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('appfl-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
