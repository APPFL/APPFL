{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Server over Secure RPC\n",
    "\n",
    "We demonstrate how to launch a gRPC server as a federated learning server with authentication. Consider only one client so that we can launch a server and a client (from another notebook) together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load server configurations\n",
    "\n",
    "In this example, we use the `FedAvg` server aggregation algoirthm (while there is only one client for easy demo, the aggregation algorithm does not matter a lot though) and the MNIST dataset by loading the server configurations from `examples/resources/configs/mnist/server_fedavg.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_configs:\n",
      "  train_configs:\n",
      "    trainer: VanillaTrainer\n",
      "    mode: step\n",
      "    num_local_steps: 100\n",
      "    optim: Adam\n",
      "    optim_args:\n",
      "      lr: 0.001\n",
      "    loss_fn_path: ./resources/loss/celoss.py\n",
      "    loss_fn_name: CELoss\n",
      "    do_validation: true\n",
      "    do_pre_validation: true\n",
      "    metric_path: ./resources/metric/acc.py\n",
      "    metric_name: accuracy\n",
      "    use_dp: false\n",
      "    epsilon: 1\n",
      "    clip_grad: false\n",
      "    clip_value: 1\n",
      "    clip_norm: 1\n",
      "    train_batch_size: 64\n",
      "    val_batch_size: 64\n",
      "    train_data_shuffle: true\n",
      "    val_data_shuffle: false\n",
      "  model_configs:\n",
      "    model_path: ./resources/model/cnn.py\n",
      "    model_name: CNN\n",
      "    model_kwargs:\n",
      "      num_channel: 1\n",
      "      num_classes: 10\n",
      "      num_pixel: 28\n",
      "  comm_configs:\n",
      "    compressor_configs:\n",
      "      enable_compression: true\n",
      "      lossy_compressor: SZ2Compressor\n",
      "      lossless_compressor: blosc\n",
      "      error_bounding_mode: REL\n",
      "      error_bound: 0.001\n",
      "      param_cutoff: 1024\n",
      "server_configs:\n",
      "  scheduler: SyncScheduler\n",
      "  scheduler_kwargs:\n",
      "    num_clients: 2\n",
      "    same_init_model: true\n",
      "  aggregator: FedAvgAggregator\n",
      "  aggregator_kwargs:\n",
      "    client_weights_mode: equal\n",
      "  device: cpu\n",
      "  num_global_epochs: 10\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "  comm_configs:\n",
      "    grpc_configs:\n",
      "      server_uri: localhost:50051\n",
      "      max_message_size: 1048576\n",
      "      use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "server_config_file = \"../../examples/resources/configs/mnist/server_fedavg.yaml\"\n",
    "server_config = OmegaConf.load(server_config_file)\n",
    "print(OmegaConf.to_yaml(server_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° It should be noted that configuration fields such as `loss_fn_path`, `metric_path`, and `model_path` are the paths to the corresponding files, so we need to change their relative paths now to make sure the paths point to the right files. \n",
    "\n",
    "‚ö†Ô∏è We also need change `num_clients` in `server_configs.scheduler_kwargs` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_config.client_configs.train_configs.loss_fn_path = '../../examples/resources/loss/celoss.py'\n",
    "server_config.client_configs.train_configs.metric_path = '../../examples/resources/metric/acc.py'\n",
    "server_config.client_configs.model_configs.model_path = '../../examples/resources/model/cnn.py'\n",
    "server_config.server_configs.scheduler_kwargs.num_clients = num_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL server and authenticator\n",
    "\n",
    "Secure SSL server requires both *public certificate* and *private key* for data encryption. We have provided a example pair of [certificate](../../src/appfl/comm/grpc/credentials/localhost.crt) and [key](../../src/appfl/comm/grpc/credentials/localhost.key) for demonstration. **It should be noted that in practice, you should never share your key to others and keep it secretly**. \n",
    "\n",
    "To enable the SSL channel and use the provided certificate and key, we need to set the following. If the user would like to use his own certificate and key, just change the corresponding field to the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_config.server_configs.comm_configs.grpc_configs.use_ssl = True\n",
    "server_config.server_configs.comm_configs.grpc_configs.server_certificate_key = '../../src/appfl/comm/grpc/credentials/localhost.key'\n",
    "server_config.server_configs.comm_configs.grpc_configs.server_certificate = '../../src/appfl/comm/grpc/credentials/localhost.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup an authenticator\n",
    "\n",
    "Now we use a naive authenticator, where the server sets a special token and uses token-match to authenticate the client. \n",
    "\n",
    "üí° It should be noted that the naive authenticator is only for easy demonstration and is not really safe in practice to protect your FL experiment. We also provide Globus authenticator, and you can also define your own ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_config.server_configs.comm_configs.grpc_configs.use_authenticator = True\n",
    "server_config.server_configs.comm_configs.grpc_configs.authenticator = \"NaiveAuthenticator\"\n",
    "server_config.server_configs.comm_configs.grpc_configs.authenticator_args = {\"auth_token\": \"A_SECRET_DEMO_TOKEN\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start server\n",
    "\n",
    "Now, we are ready to create the server agent using the `server_config` defined and modified above and start the grpc server.\n",
    "\n",
    "After launching üöÄ the server, let's go to the notebook to launch the client to talk to the server!\n",
    "\n",
    "üí° After finishing the FL experiment, you need to manually stop the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Zilinghans-MBP.attlocal.net:67073] shmem: mmap: an error occurred while determining whether or not /var/folders/b_/gwq73k4j7z53_f2qmdwcl22w0000gp/T//ompi.Zilinghans-MBP.502/jf.0/4255842304/sm_segment.Zilinghans-MBP.502.fdab0000.0 could be created.\n",
      "[2024-08-23 19:54:40,240 INFO server]: Logging to ./output/result_Server_2024-08-23-19:54:40.txt\n",
      "[2024-08-23 19:54:40,240 INFO server]: Setting seed value to 42\n",
      "[2024-08-23 19:54:57,923 INFO server]: Received GetConfiguration request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:54:57,935 INFO server]: Received GetGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:54:57,945 INFO server]: Received InvokeCustomAction set_sample_size request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:01,804 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:05,669 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:09,539 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:13,425 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:17,342 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:21,223 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:25,115 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:29,004 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:32,926 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:36,830 INFO server]: Received UpdateGlobalModel request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n",
      "[2024-08-23 19:55:36,873 INFO server]: Received InvokeCustomAction close_connection request from client fe3dff7b-6486-43de-a489-d2724cb6947b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating the server ...\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ServerAgent\n",
    "from appfl.comm.grpc import GRPCServerCommunicator, serve\n",
    "server_agent = ServerAgent(server_agent_config=server_config)\n",
    "\n",
    "communicator = GRPCServerCommunicator(\n",
    "    server_agent,\n",
    "    max_message_size=server_config.server_configs.comm_configs.grpc_configs.max_message_size,\n",
    "    logger=server_agent.logger,\n",
    ")\n",
    "\n",
    "serve(\n",
    "    communicator,\n",
    "    **server_config.server_configs.comm_configs.grpc_configs,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a3775820edfef7d27663833b7a57b274657051daef716a62aaac9a7002010d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('appfl-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
