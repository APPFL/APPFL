{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to set configuration\n",
    "\n",
    "All runs use [OmegaConf](https://omegaconf.readthedocs.io/), a hierarchical configuration system.\n",
    "\n",
    "## Load default configuration\n",
    "\n",
    "Every run requires to set the configuration defined in `DictConfig` format. We can easily load the default configuration setting by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appfl.config import *\n",
    "cfg: DictConfig = OmegaConf.structured(Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration `cfg` is initialized with the default values. Let's check the configuration values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fed:\n",
      "  type: fedavg\n",
      "  servername: FedAvgServer\n",
      "  clientname: FedAvgClient\n",
      "  args:\n",
      "    num_local_epochs: 1\n",
      "    loss_type: torch.nn.CrossEntropyLoss()\n",
      "    optim: SGD\n",
      "    optim_args:\n",
      "      lr: 0.01\n",
      "      momentum: 0.9\n",
      "      weight_decay: 1.0e-05\n",
      "    epsilon: false\n",
      "    clip_value: false\n",
      "    clip_norm: 1\n",
      "num_epochs: 2\n",
      "batch_training: true\n",
      "train_data_batch_size: 64\n",
      "train_data_shuffle: false\n",
      "test_data_batch_size: 64\n",
      "test_data_shuffle: false\n",
      "load_model: false\n",
      "load_model_dirname: ''\n",
      "load_model_filename: ''\n",
      "save_model: false\n",
      "save_model_dirname: ''\n",
      "save_model_filename: ''\n",
      "output_dirname: ./outputs\n",
      "output_filename: result\n",
      "device: cpu\n",
      "validation: true\n",
      "max_message_size: 10485760\n",
      "operator:\n",
      "  id: 1\n",
      "server:\n",
      "  id: 1\n",
      "  host: localhost\n",
      "  port: 50051\n",
      "  use_tls: false\n",
      "  api_key: null\n",
      "client:\n",
      "  id: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most variables are self-explanatory.\n",
    "\n",
    "- Variable ``fed`` sets the choice of algorithms, each of which is also defined as a dataclass. The classes should be accessible by ``appfl.config.fed.*``. \n",
    "- gRPC configurations:\n",
    "  - ``max_message_size``: the maximum size of data to be sent or received in a single RPC call, default 10 MB. If the size of weights for a single neuron is larger than 10 MB, you need to increase this value.\n",
    "  - ``host``: the URL of a server\n",
    "  - ``port``: the port number of a server\n",
    "\n",
    "\n",
    "## Initialize configuration with arguments\n",
    "\n",
    "We can also initialize the configuration with other values. For example, the following code is loading the configuration with the algorithm choice of `IIADMM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: iiadmm\n",
      "servername: IIADMMServer\n",
      "clientname: IIADMMClient\n",
      "args:\n",
      "  num_local_epochs: 1\n",
      "  loss_type: torch.nn.CrossEntropyLoss()\n",
      "  accum_grad: true\n",
      "  coeff_grad: false\n",
      "  optim: SGD\n",
      "  optim_args:\n",
      "    lr: 0.01\n",
      "  init_penalty: 100.0\n",
      "  residual_balancing:\n",
      "    res_on: false\n",
      "    res_on_every_update: false\n",
      "    tau: 1.1\n",
      "    mu: 10\n",
      "  epsilon: false\n",
      "  clip_value: false\n",
      "  clip_norm: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg: DictConfig = OmegaConf.structured(Config(\n",
    "    fed = fed.iiadmm.IIADMM()\n",
    "))\n",
    "print(OmegaConf.to_yaml(cfg.fed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change configuration values\n",
    "\n",
    "We can also change the configuration value after initialization. For example, we can change `fed` variable as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: fedavg\n",
      "servername: FedAvgServer\n",
      "clientname: FedAvgClient\n",
      "args:\n",
      "  num_local_epochs: 1\n",
      "  loss_type: torch.nn.CrossEntropyLoss()\n",
      "  optim: SGD\n",
      "  optim_args:\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    weight_decay: 1.0e-05\n",
      "  epsilon: false\n",
      "  clip_value: false\n",
      "  clip_norm: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg: DictConfig = OmegaConf.structured(Config)\n",
    "my_fed: DictConfig = OmegaConf.structured(fed.fedavg.FedAvg)\n",
    "cfg.fed = my_fed\n",
    "print(OmegaConf.to_yaml(cfg.fed))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "201a1c907cd37941086a5fb94e489fb327239b7be498e5e7c17d65ce8de3610b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('APPFL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
