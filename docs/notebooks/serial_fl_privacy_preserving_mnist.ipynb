{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6yBJqLc2ov_Z"
   },
   "outputs": [],
   "source": [
    "num_clients = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CFD4VyXTP4uW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_configs:\n",
      "  train_configs:\n",
      "    trainer: VanillaTrainer\n",
      "    dp_mechanism: opacus\n",
      "    dp_config:\n",
      "      noise_multiplier: 1.0\n",
      "      max_grad_norm: 1.0\n",
      "    mode: step\n",
      "    num_local_steps: 100\n",
      "    optim: Adam\n",
      "    optim_args:\n",
      "      lr: 0.01\n",
      "    loss_fn_path: ./resources/loss/celoss.py\n",
      "    loss_fn_name: CELoss\n",
      "    do_validation: true\n",
      "    do_pre_validation: true\n",
      "    metric_path: ./resources/metric/acc.py\n",
      "    metric_name: accuracy\n",
      "    use_dp: true\n",
      "    epsilon: 1\n",
      "    clip_grad: false\n",
      "    clip_value: 1\n",
      "    clip_norm: 1\n",
      "    train_batch_size: 64\n",
      "    val_batch_size: 64\n",
      "    train_data_shuffle: true\n",
      "    val_data_shuffle: false\n",
      "  model_configs:\n",
      "    model_path: ./resources/model/resnet.py\n",
      "    model_name: ResNet18\n",
      "  comm_configs:\n",
      "    compressor_configs:\n",
      "      enable_compression: false\n",
      "      lossy_compressor: SZ2Compressor\n",
      "      lossless_compressor: blosc\n",
      "      error_bounding_mode: REL\n",
      "      error_bound: 0.001\n",
      "      param_cutoff: 1024\n",
      "server_configs:\n",
      "  num_clients: 2\n",
      "  scheduler: SyncScheduler\n",
      "  scheduler_kwargs:\n",
      "    same_init_model: true\n",
      "  aggregator: FedAvgAggregator\n",
      "  aggregator_kwargs:\n",
      "    client_weights_mode: equal\n",
      "  device: cpu\n",
      "  num_global_epochs: 20\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "  comm_configs:\n",
      "    grpc_configs:\n",
      "      server_uri: localhost:50051\n",
      "      max_message_size: 1048576\n",
      "      use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "server_config_file = \"../../examples/resources/configs/cifar10/server_fedavg.yaml\"\n",
    "server_config = OmegaConf.load(server_config_file)\n",
    "print(OmegaConf.to_yaml(server_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z6MpnwsAQBuY"
   },
   "outputs": [],
   "source": [
    "server_config.client_configs.train_configs.loss_fn_path = (\n",
    "    \"../../examples/resources/loss/celoss.py\"\n",
    ")\n",
    "server_config.client_configs.train_configs.metric_path = (\n",
    "    \"../../examples/resources/metric/acc.py\"\n",
    ")\n",
    "server_config.client_configs.model_configs.model_path = \"\"\n",
    "\n",
    "if server_config.client_configs.train_configs[\"use_dp\"] and (\n",
    "    server_config.client_configs.train_configs[\"dp_mechanism\"] == \"opacus\"\n",
    "):\n",
    "    server_config.client_configs.model_configs.model_path = (\n",
    "        \"../../examples/resources/model/resnet_opacus.py\"\n",
    "    )\n",
    "else:\n",
    "    server_config.client_configs.model_configs.model_path = (\n",
    "        \"../../examples/resources/model/resnet.py\"\n",
    "    )\n",
    "\n",
    "server_config.server_configs.num_global_epochs = 3\n",
    "server_config.server_configs.num_clients = num_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yPYckLohQKIa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id: Client1\n",
      "train_configs:\n",
      "  device: cuda\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "data_configs:\n",
      "  dataset_path: ./resources/dataset/cifar10_dataset.py\n",
      "  dataset_name: get_cifar10\n",
      "  dataset_kwargs:\n",
      "    num_clients: 2\n",
      "    client_id: 0\n",
      "    partition_strategy: class_noniid\n",
      "    visualization: true\n",
      "    output_dirname: ./output\n",
      "    output_filename: visualization.pdf\n",
      "comm_configs:\n",
      "  grpc_configs:\n",
      "    server_uri: localhost:50051\n",
      "    max_message_size: 1048576\n",
      "    use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client_config_file = \"../../examples/resources/configs/cifar10/client_1.yaml\"\n",
    "client_config = OmegaConf.load(client_config_file)\n",
    "print(OmegaConf.to_yaml(client_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ypPYMceKQQae"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "client_configs = [copy.deepcopy(client_config) for _ in range(num_clients)]\n",
    "for i in range(num_clients):\n",
    "    client_configs[i].client_id = f\"Client{i + 1}\"\n",
    "    client_configs[\n",
    "        i\n",
    "    ].data_configs.dataset_path = \"../../examples/resources/dataset/cifar10_dataset.py\"\n",
    "    client_configs[i].data_configs.dataset_kwargs.num_clients = num_clients\n",
    "    client_configs[i].data_configs.dataset_kwargs.client_id = i\n",
    "    client_configs[i].data_configs.dataset_kwargs.visualization = (\n",
    "        True if i == 0 else False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ViCZ7rpQanV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:27:50,986 server]: Logging to ./output/result_Server_2025-09-16-16-27-50.txt\n",
      "09/16/2025 16:27:50:INFO:Logging to ./output/result_Server_2025-09-16-16-27-50.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:27:51,023 Client1]: Logging to ./output/result_Client1_2025-09-16-16-27-51.txt\n",
      "09/16/2025 16:27:51:INFO:Logging to ./output/result_Client1_2025-09-16-16-27-51.txt\n",
      "100%|██████████| 170M/170M [00:48<00:00, 3.51MB/s] \n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:28:55,826 Client2]: Logging to ./output/result_Client2_2025-09-16-16-28-55.txt\n",
      "09/16/2025 16:28:55:INFO:Logging to ./output/result_Client2_2025-09-16-16-28-55.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:29:11,133 Client3]: Logging to ./output/result_Client3_2025-09-16-16-29-11.txt\n",
      "09/16/2025 16:29:11:INFO:Logging to ./output/result_Client3_2025-09-16-16-29-11.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:29:26,515 Client4]: Logging to ./output/result_Client4_2025-09-16-16-29-26.txt\n",
      "09/16/2025 16:29:26:INFO:Logging to ./output/result_Client4_2025-09-16-16-29-26.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:29:41,806 Client5]: Logging to ./output/result_Client5_2025-09-16-16-29-41.txt\n",
      "09/16/2025 16:29:41:INFO:Logging to ./output/result_Client5_2025-09-16-16-29-41.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:29:57,758 Client6]: Logging to ./output/result_Client6_2025-09-16-16-29-57.txt\n",
      "09/16/2025 16:29:57:INFO:Logging to ./output/result_Client6_2025-09-16-16-29-57.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:30:13,516 Client7]: Logging to ./output/result_Client7_2025-09-16-16-30-13.txt\n",
      "09/16/2025 16:30:13:INFO:Logging to ./output/result_Client7_2025-09-16-16-30-13.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:30:29,068 Client8]: Logging to ./output/result_Client8_2025-09-16-16-30-29.txt\n",
      "09/16/2025 16:30:29:INFO:Logging to ./output/result_Client8_2025-09-16-16-30-29.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:30:44,307 Client9]: Logging to ./output/result_Client9_2025-09-16-16-30-44.txt\n",
      "09/16/2025 16:30:44:INFO:Logging to ./output/result_Client9_2025-09-16-16-30-44.txt\n",
      "\u001b[34m\u001b[1mappfl: ✅\u001b[0m[2025-09-16 16:30:59,589 Client10]: Logging to ./output/result_Client10_2025-09-16-16-30-59.txt\n",
      "09/16/2025 16:30:59:INFO:Logging to ./output/result_Client10_2025-09-16-16-30-59.txt\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ServerAgent, ClientAgent\n",
    "\n",
    "server_agent = ServerAgent(server_agent_config=server_config)\n",
    "client_agents = [\n",
    "    ClientAgent(client_agent_config=client_configs[i]) for i in range(num_clients)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g2pZn6SDQiS_"
   },
   "outputs": [],
   "source": [
    "# Get additional client configurations from the server\n",
    "client_config_from_server = server_agent.get_client_configs()\n",
    "for client_agent in client_agents:\n",
    "    client_agent.load_config(client_config_from_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tDdurRczQte4"
   },
   "outputs": [],
   "source": [
    "# Load initial global model from the server\n",
    "init_global_model = server_agent.get_parameters(serial_run=True)\n",
    "for client_agent in client_agents:\n",
    "    client_agent.load_parameters(init_global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "N3E7wPVQQvo6"
   },
   "outputs": [],
   "source": [
    "# [Optional] Set number of local data to the server\n",
    "for i in range(num_clients):\n",
    "    sample_size = client_agents[i].get_sample_size()\n",
    "    server_agent.set_sample_size(\n",
    "        client_id=client_agents[i].get_id(), sample_size=sample_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sLKW6dMuQyQX"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m new_global_models \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client_agent \u001b[38;5;129;01min\u001b[39;00m client_agents:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Client local training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mclient_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     local_model \u001b[38;5;241m=\u001b[39m client_agent\u001b[38;5;241m.\u001b[39mget_parameters()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(local_model, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/projects/appfl/appfl-release/src/appfl/agent/client.py:123\u001b[0m, in \u001b[0;36mClientAgent.train\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model locally.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Memory optimization: Garbage collection after training\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_memory:\n",
      "File \u001b[0;32m~/Documents/projects/appfl/appfl-release/src/appfl/algorithm/trainer/vanilla_trainer.py:111\u001b[0m, in \u001b[0;36mVanillaTrainer.train\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_prev \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Configure model for possible DataParallel\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mapply_model_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m do_validation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    117\u001b[0m do_pre_validation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_pre_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    120\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/appfl/appfl-release/src/appfl/misc/utils.py:609\u001b[0m, in \u001b[0;36mapply_model_device\u001b[0;34m(model, config, xy_device)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu-single\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;66;03m# Single GPU\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;66;03m# device is `cuda` without index\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         device_id \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/appfl/lib/python3.10/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/appfl/lib/python3.10/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/appfl/lib/python3.10/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/appfl/lib/python3.10/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/appfl/lib/python3.10/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "while not server_agent.training_finished():\n",
    "    new_global_models = []\n",
    "    for client_agent in client_agents:\n",
    "        # Client local training\n",
    "        client_agent.train()\n",
    "        local_model = client_agent.get_parameters()\n",
    "        if isinstance(local_model, tuple):\n",
    "            local_model, metadata = local_model[0], local_model[1]\n",
    "        else:\n",
    "            metadata = {}\n",
    "        # \"Send\" local model to server and get a Future object for the new global model\n",
    "        # The Future object will be resolved when the server receives local models from all clients\n",
    "        new_global_model_future = server_agent.global_update(\n",
    "            client_id=client_agent.get_id(),\n",
    "            local_model=local_model,\n",
    "            blocking=False,\n",
    "            **metadata,\n",
    "        )\n",
    "        new_global_models.append(new_global_model_future)\n",
    "    # Load the new global model from the server\n",
    "    for client_agent, new_global_model_future in zip(client_agents, new_global_models):\n",
    "        client_agent.load_parameters(new_global_model_future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "appfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
