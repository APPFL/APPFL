{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Client over Secure RPC\n",
    "\n",
    "In this notebook, we will present how to launch a gRPC client as an FL client with an authenticator. To pair with the server notebook, we consider only one client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load client configurations\n",
    "\n",
    "We load the configuration for the client from `examples/resources/configs/mnist/client_1.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_configs:\n",
      "  device: cpu\n",
      "  logging_id: Client1\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "data_configs:\n",
      "  dataset_path: ./resources/dataset/mnist_dataset.py\n",
      "  dataset_name: get_mnist\n",
      "  dataset_kwargs:\n",
      "    num_clients: 2\n",
      "    client_id: 0\n",
      "    partition_strategy: class_noniid\n",
      "    visualization: true\n",
      "    output_dirname: ./output\n",
      "    output_filename: visualization.pdf\n",
      "comm_configs:\n",
      "  grpc_configs:\n",
      "    server_uri: localhost:50051\n",
      "    max_message_size: 1048576\n",
      "    use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "client_config_file = \"../../examples/resources/configs/mnist/client_1.yaml\"\n",
    "client_config = OmegaConf.load(client_config_file)\n",
    "print(OmegaConf.to_yaml(client_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We need to change the relative path in `data_configs.dataset_path` to point to the right file relative to this notebook.\n",
    "\n",
    "üí° We also need to change `data_configs.dataset_kwargs.num_clients` to 1 to make sure we only partition the MNIST dataset to one client split. We change `data_configs.dataset_kwargs.visualization` to False as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.data_configs.dataset_path = (\n",
    "    \"../../examples/resources/dataset/mnist_dataset.py\"\n",
    ")\n",
    "client_config.data_configs.dataset_kwargs.num_clients = num_clients\n",
    "client_config.data_configs.dataset_kwargs.visualization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL channel and authenticator\n",
    "\n",
    "The client requires a root certificate to verify the server certificate. In this example, we provide that [root certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/root.crt), assuming that the server uses self-signed [certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.crt) and [key](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.key) provided by gRPC official documentation.\n",
    "\n",
    "üí° Please check this [tutorial](https://appfl.ai/en/latest/tutorials/examples_ssl.html) for more details on how to generate SSL certificates for securing the gRPC connections in practice.\n",
    "\n",
    "To use the provided root certificate, user just to need to set the following. If the user would like to use his own root certificate, just change this to the file path to the local root certificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_ssl = True\n",
    "client_config.comm_configs.grpc_configs.root_certificate = (\n",
    "    \"../../src/appfl/comm/grpc/credentials/root.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set configurations to use the naive authenticator and provide the `auth_token` agreed with the server for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_authenticator = True\n",
    "client_config.comm_configs.grpc_configs.authenticator = \"NaiveAuthenticator\"\n",
    "client_config.comm_configs.grpc_configs.authenticator_args = {\n",
    "    \"auth_token\": \"A_SECRET_DEMO_TOKEN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the client agent and communicator\n",
    "\n",
    "Now we are ready to create the client agent using the `client_agent` defined and modified above, as well as a `GRPCClientCommunicator` to send request to the server.\n",
    "\n",
    "‚ö†Ô∏è Please make sure that you have started the server from the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-01 22:33:19,594 INFO Client1]: Logging to ./output/result_Client1_2024-12-01-22:33:19.txt\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ClientAgent\n",
    "from appfl.comm.grpc import GRPCClientCommunicator\n",
    "\n",
    "client_agent = ClientAgent(client_agent_config=client_config)\n",
    "client_communicator = GRPCClientCommunicator(\n",
    "    client_id=client_agent.get_id(),\n",
    "    **client_config.comm_configs.grpc_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the FL experiment\n",
    "\n",
    "Client start the FL experiment by doing the following things:\n",
    "\n",
    "- Obtain general client-side configurations from the server and load them\n",
    "- Obtain the initial global model from the server\n",
    "- *[Optional]* Send the number of local data to the server\n",
    "- Iteratively train the model and update the global model until receiving a `DONE` status flag from the server.\n",
    "\n",
    "üí° The server is also logging several information regarding the recipe of client requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-01 22:33:26,774 INFO Client1]:      Round   Pre Val?       Time Train Loss Train Accuracy   Val Loss Val Accuracy\n",
      "[2024-12-01 22:33:27,804 INFO Client1]:          0          Y                                          2.3006      15.9300\n",
      "[2024-12-01 22:33:30,882 INFO Client1]:          0          N     3.0764     0.0660        80.5469     0.1735      94.8800\n",
      "[2024-12-01 22:33:32,014 INFO Client1]:          1          Y                                          0.1735      94.8800\n",
      "[2024-12-01 22:33:34,984 INFO Client1]:          1          N     2.9692     0.0165        95.1094     0.1086      96.5300\n",
      "[2024-12-01 22:33:36,100 INFO Client1]:          2          Y                                          0.1086      96.5300\n",
      "[2024-12-01 22:33:39,105 INFO Client1]:          2          N     3.0045     0.0130        96.1250     0.0678      97.7900\n",
      "[2024-12-01 22:33:40,187 INFO Client1]:          3          Y                                          0.0678      97.7900\n",
      "[2024-12-01 22:33:43,114 INFO Client1]:          3          N     2.9257     0.0096        97.1562     0.0987      96.9600\n",
      "[2024-12-01 22:33:44,186 INFO Client1]:          4          Y                                          0.0987      96.9600\n",
      "[2024-12-01 22:33:47,170 INFO Client1]:          4          N     2.9828     0.0075        97.8750     0.0565      98.2100\n",
      "[2024-12-01 22:33:48,255 INFO Client1]:          5          Y                                          0.0565      98.2100\n",
      "[2024-12-01 22:33:51,306 INFO Client1]:          5          N     3.0496     0.0082        97.7188     0.0542      98.3400\n",
      "[2024-12-01 22:33:52,389 INFO Client1]:          6          Y                                          0.0542      98.3400\n",
      "[2024-12-01 22:33:55,529 INFO Client1]:          6          N     3.1387     0.0057        98.3281     0.0607      97.9800\n",
      "[2024-12-01 22:33:56,632 INFO Client1]:          7          Y                                          0.0607      97.9800\n",
      "[2024-12-01 22:33:59,599 INFO Client1]:          7          N     2.9659     0.0055        98.2031     0.0460      98.5100\n",
      "[2024-12-01 22:34:00,694 INFO Client1]:          8          Y                                          0.0460      98.5100\n",
      "[2024-12-01 22:34:03,702 INFO Client1]:          8          N     3.0068     0.0061        98.2656     0.0485      98.2900\n",
      "[2024-12-01 22:34:04,806 INFO Client1]:          9          Y                                          0.0485      98.2900\n",
      "[2024-12-01 22:34:07,975 INFO Client1]:          9          N     3.1678     0.0056        98.5469     0.0412      98.5900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain general client-side configurations from the server and load them\n",
    "client_config = client_communicator.get_configuration()\n",
    "client_agent.load_config(client_config)\n",
    "\n",
    "# Obtain the initial global model from the server\n",
    "init_global_model = client_communicator.get_global_model(init_model=True)\n",
    "client_agent.load_parameters(init_global_model)\n",
    "\n",
    "# Send the number of local data to the server\n",
    "sample_size = client_agent.get_sample_size()\n",
    "client_communicator.invoke_custom_action(\n",
    "    action=\"set_sample_size\", sample_size=sample_size\n",
    ")\n",
    "\n",
    "while True:\n",
    "    client_agent.train()\n",
    "    local_model = client_agent.get_parameters()\n",
    "    if isinstance(local_model, tuple):\n",
    "        local_model, meta_data_local = local_model[0], local_model[1]\n",
    "    else:\n",
    "        meta_data_local = {}\n",
    "    new_global_model, metadata = client_communicator.update_global_model(\n",
    "        local_model, **meta_data_local\n",
    "    )\n",
    "    if metadata[\"status\"] == \"DONE\":\n",
    "        break\n",
    "    client_agent.load_parameters(new_global_model)\n",
    "client_communicator.invoke_custom_action(action=\"close_connection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
