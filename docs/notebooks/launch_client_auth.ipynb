{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Client over Secure RPC\n",
    "\n",
    "In this notebook, we will present how to launch a gRPC client as an FL client with an authenticator. To pair with the server notebook, we consider only one client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load client configurations\n",
    "\n",
    "We load the configuration for the client from `examples/resources/configs/mnist/client_1.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_configs:\n",
      "  device: cpu\n",
      "  logging_id: Client1\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "data_configs:\n",
      "  dataset_path: ./resources/dataset/mnist_dataset.py\n",
      "  dataset_name: get_mnist\n",
      "  dataset_kwargs:\n",
      "    num_clients: 2\n",
      "    client_id: 0\n",
      "    partition_strategy: class_noniid\n",
      "    visualization: true\n",
      "    output_dirname: ./output\n",
      "    output_filename: visualization.pdf\n",
      "comm_configs:\n",
      "  grpc_configs:\n",
      "    server_uri: localhost:50051\n",
      "    max_message_size: 1048576\n",
      "    use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "client_config_file = \"../../examples/resources/configs/mnist/client_1.yaml\"\n",
    "client_config = OmegaConf.load(client_config_file)\n",
    "print(OmegaConf.to_yaml(client_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We need to change the relative path in `data_configs.dataset_path` to point to the right file relative to this notebook.\n",
    "\n",
    "üí° We also need to change `data_configs.dataset_kwargs.num_clients` to 1 to make sure we only partition the MNIST dataset to one client split. We change `data_configs.dataset_kwargs.visualization` to False as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.data_configs.dataset_path = (\n",
    "    \"../../examples/resources/dataset/mnist_dataset.py\"\n",
    ")\n",
    "client_config.data_configs.dataset_kwargs.num_clients = num_clients\n",
    "client_config.data_configs.dataset_kwargs.visualization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL channel and authenticator\n",
    "\n",
    "The client requires a root certificate to verify the server certificate. In this example, we provide that [root certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/root.crt), assuming that the server uses self-signed [certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.crt) and [key](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.key) provided by gRPC official documentation.\n",
    "\n",
    "To use the provided root certificate, user just to need to set the following. If the user would like to use his own root certificate, just change this to the file path to the local root certificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_ssl = True\n",
    "client_config.comm_configs.grpc_configs.root_certificate = (\n",
    "    \"../../src/appfl/comm/grpc/credentials/root.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set configurations to use the naive authenticator and provide the `auth_token` agreed with the server for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_authenticator = True\n",
    "client_config.comm_configs.grpc_configs.authenticator = \"NaiveAuthenticator\"\n",
    "client_config.comm_configs.grpc_configs.authenticator_args = {\n",
    "    \"auth_token\": \"A_SECRET_DEMO_TOKEN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the client agent and communicator\n",
    "\n",
    "Now we are ready to create the client agent using the `client_agent` defined and modified above, as well as a `GRPCClientCommunicator` to send request to the server.\n",
    "\n",
    "‚ö†Ô∏è Please make sure that you have started the server from the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Zilinghans-MBP.attlocal.net:67058] shmem: mmap: an error occurred while determining whether or not /var/folders/b_/gwq73k4j7z53_f2qmdwcl22w0000gp/T//ompi.Zilinghans-MBP.502/jf.0/1732640768/sm_segment.Zilinghans-MBP.502.67460000.0 could be created.\n",
      "[2024-08-23 19:54:50,746 INFO Client1]: Logging to ./output/result_Client1_2024-08-23-19:54:50.txt\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ClientAgent\n",
    "from appfl.comm.grpc import GRPCClientCommunicator\n",
    "\n",
    "client_agent = ClientAgent(client_agent_config=client_config)\n",
    "client_communicator = GRPCClientCommunicator(\n",
    "    client_id=client_agent.get_id(),\n",
    "    **client_config.comm_configs.grpc_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the FL experiment\n",
    "\n",
    "Client start the FL experiment by doing the following things:\n",
    "\n",
    "- Obtain general client-side configurations from the server and load them\n",
    "- Obtain the initial global model from the server\n",
    "- *[Optional]* Send the number of local data to the server\n",
    "- Iteratively train the model and update the global model until receiving a `DONE` status flag from the server.\n",
    "\n",
    "üí° The server is also logging several information regarding the recipe of client requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-23 19:54:57,946 INFO Client1]:      Round   Pre Val?       Time Train Loss Train Accuracy   Val Loss Val Accuracy\n",
      "[2024-08-23 19:54:58,969 INFO Client1]:          0          Y                                          2.3006      15.9300\n",
      "[2024-08-23 19:55:01,773 INFO Client1]:          0          N     2.8036     0.0612        82.4375     0.1884      94.2200\n",
      "[2024-08-23 19:55:02,870 INFO Client1]:          1          Y                                          0.1885      94.2200\n",
      "[2024-08-23 19:55:05,643 INFO Client1]:          1          N     2.7727     0.0168        95.0781     0.1219      96.1600\n",
      "[2024-08-23 19:55:06,743 INFO Client1]:          2          Y                                          0.1219      96.1600\n",
      "[2024-08-23 19:55:09,514 INFO Client1]:          2          N     2.7699     0.0126        96.3281     0.0819      97.3200\n",
      "[2024-08-23 19:55:10,609 INFO Client1]:          3          Y                                          0.0818      97.3300\n",
      "[2024-08-23 19:55:13,400 INFO Client1]:          3          N     2.7903     0.0098        97.0469     0.0635      97.7700\n",
      "[2024-08-23 19:55:14,505 INFO Client1]:          4          Y                                          0.0635      97.7700\n",
      "[2024-08-23 19:55:17,316 INFO Client1]:          4          N     2.8109     0.0078        97.6250     0.0530      98.3400\n",
      "[2024-08-23 19:55:18,425 INFO Client1]:          5          Y                                          0.0530      98.3400\n",
      "[2024-08-23 19:55:21,197 INFO Client1]:          5          N     2.7714     0.0066        98.0312     0.0598      98.0200\n",
      "[2024-08-23 19:55:22,298 INFO Client1]:          6          Y                                          0.0598      98.0200\n",
      "[2024-08-23 19:55:25,090 INFO Client1]:          6          N     2.7909     0.0059        98.2344     0.0431      98.5900\n",
      "[2024-08-23 19:55:26,181 INFO Client1]:          7          Y                                          0.0431      98.5900\n",
      "[2024-08-23 19:55:28,979 INFO Client1]:          7          N     2.7970     0.0059        97.9219     0.0561      98.1900\n",
      "[2024-08-23 19:55:30,093 INFO Client1]:          8          Y                                          0.0561      98.1800\n",
      "[2024-08-23 19:55:32,901 INFO Client1]:          8          N     2.8076     0.0048        98.5469     0.0444      98.5700\n",
      "[2024-08-23 19:55:34,012 INFO Client1]:          9          Y                                          0.0445      98.5700\n",
      "[2024-08-23 19:55:36,805 INFO Client1]:          9          N     2.7918     0.0057        98.4688     0.0492      98.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain general client-side configurations from the server and load them\n",
    "client_config = client_communicator.get_configuration()\n",
    "client_agent.load_config(client_config)\n",
    "\n",
    "# Obtain the initial global model from the server\n",
    "init_global_model = client_communicator.get_global_model(init_model=True)\n",
    "client_agent.load_parameters(init_global_model)\n",
    "\n",
    "# Send the number of local data to the server\n",
    "sample_size = client_agent.get_sample_size()\n",
    "client_communicator.invoke_custom_action(\n",
    "    action=\"set_sample_size\", sample_size=sample_size\n",
    ")\n",
    "\n",
    "while True:\n",
    "    client_agent.train()\n",
    "    local_model = client_agent.get_parameters()\n",
    "    new_global_model, metadata = client_communicator.update_global_model(local_model)\n",
    "    if metadata[\"status\"] == \"DONE\":\n",
    "        break\n",
    "    client_agent.load_parameters(new_global_model)\n",
    "client_communicator.invoke_custom_action(action=\"close_connection\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5a3775820edfef7d27663833b7a57b274657051daef716a62aaac9a7002010d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('appfl-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
