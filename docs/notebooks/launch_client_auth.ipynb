{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Client over Secure RPC\n",
    "\n",
    "In this notebook, we will present how to launch a gRPC client as an FL client with an authenticator. To pair with the server notebook, we consider only one client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load client configurations\n",
    "\n",
    "We load the configuration for the client from `examples/resources/configs/mnist/client_1.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id: Client1\n",
      "train_configs:\n",
      "  device: cpu\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "data_configs:\n",
      "  dataset_path: ./resources/dataset/mnist_dataset.py\n",
      "  dataset_name: get_mnist\n",
      "  dataset_kwargs:\n",
      "    num_clients: 2\n",
      "    client_id: 0\n",
      "    partition_strategy: class_noniid\n",
      "    visualization: true\n",
      "    output_dirname: ./output\n",
      "    output_filename: visualization.pdf\n",
      "comm_configs:\n",
      "  grpc_configs:\n",
      "    server_uri: localhost:50051\n",
      "    max_message_size: 1048576\n",
      "    use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "client_config_file = \"../../examples/resources/configs/mnist/client_1.yaml\"\n",
    "client_config = OmegaConf.load(client_config_file)\n",
    "print(OmegaConf.to_yaml(client_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We need to change the relative path in `data_configs.dataset_path` to point to the right file relative to this notebook.\n",
    "\n",
    "üí° We also need to change `data_configs.dataset_kwargs.num_clients` to 1 to make sure we only partition the MNIST dataset to one client split. We change `data_configs.dataset_kwargs.visualization` to False as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.data_configs.dataset_path = (\n",
    "    \"../../examples/resources/dataset/mnist_dataset.py\"\n",
    ")\n",
    "client_config.data_configs.dataset_kwargs.num_clients = num_clients\n",
    "client_config.data_configs.dataset_kwargs.visualization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL channel and authenticator\n",
    "\n",
    "The client requires a root certificate to verify the server certificate. In this example, we provide that [root certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/root.crt), assuming that the server uses self-signed [certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.crt) and [key](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.key) provided by gRPC official documentation.\n",
    "\n",
    "üí° Please check this [tutorial](https://appfl.ai/en/latest/tutorials/examples_ssl.html) for more details on how to generate SSL certificates for securing the gRPC connections in practice.\n",
    "\n",
    "To use the provided root certificate, user just to need to set the following. If the user would like to use his own root certificate, just change this to the file path to the local root certificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_ssl = True\n",
    "client_config.comm_configs.grpc_configs.root_certificate = (\n",
    "    \"../../src/appfl/comm/grpc/credentials/root.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set configurations to use the naive authenticator and provide the `auth_token` agreed with the server for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_authenticator = True\n",
    "client_config.comm_configs.grpc_configs.authenticator = \"NaiveAuthenticator\"\n",
    "client_config.comm_configs.grpc_configs.authenticator_args = {\n",
    "    \"auth_token\": \"A_SECRET_DEMO_TOKEN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the client agent and communicator\n",
    "\n",
    "Now we are ready to create the client agent using the `client_agent` defined and modified above, as well as a `GRPCClientCommunicator` to send request to the server.\n",
    "\n",
    "‚ö†Ô∏è Please make sure that you have started the server from the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:43,479 Client1]: Logging to ./output/result_Client1_2025-01-06-12-04-43.txt\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ClientAgent\n",
    "from appfl.comm.grpc import GRPCClientCommunicator\n",
    "\n",
    "client_agent = ClientAgent(client_agent_config=client_config)\n",
    "client_communicator = GRPCClientCommunicator(\n",
    "    client_id=client_agent.get_id(),\n",
    "    **client_config.comm_configs.grpc_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the FL experiment\n",
    "\n",
    "Client start the FL experiment by doing the following things:\n",
    "\n",
    "- Obtain general client-side configurations from the server and load them\n",
    "- Obtain the initial global model from the server\n",
    "- *[Optional]* Send the number of local data to the server\n",
    "- Iteratively train the model and update the global model until receiving a `DONE` status flag from the server.\n",
    "\n",
    "üí° The server is also logging several information regarding the recipe of client requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:50,276 Client1]:      Round   Pre Val?       Time Train Loss Train Accuracy   Val Loss Val Accuracy\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:51,298 Client1]:          0          Y                                          2.3006      15.9300\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:54,192 Client1]:          0          N     2.8928     0.0609        82.5156     0.2414      93.1100\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:55,249 Client1]:          1          Y                                          0.2414      93.1100\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:58,204 Client1]:          1          N     2.9543     0.0184        94.8438     0.1206      96.1000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:04:59,297 Client1]:          2          Y                                          0.1206      96.1000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:02,250 Client1]:          2          N     2.9517     0.0122        96.4531     0.0739      97.4300\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:03,342 Client1]:          3          Y                                          0.0739      97.4300\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:06,263 Client1]:          3          N     2.9197     0.0098        97.2969     0.0801      97.3700\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:07,326 Client1]:          4          Y                                          0.0801      97.3700\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:10,175 Client1]:          4          N     2.8483     0.0082        97.5000     0.0511      98.4000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:11,257 Client1]:          5          Y                                          0.0511      98.4000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:14,113 Client1]:          5          N     2.8548     0.0074        97.8594     0.0457      98.5200\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:15,194 Client1]:          6          Y                                          0.0457      98.5200\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:18,066 Client1]:          6          N     2.8716     0.0066        98.0312     0.0442      98.6000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:19,147 Client1]:          7          Y                                          0.0442      98.6000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:22,025 Client1]:          7          N     2.8765     0.0057        98.2656     0.0388      98.7700\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:23,098 Client1]:          8          Y                                          0.0388      98.7700\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:25,968 Client1]:          8          N     2.8691     0.0048        98.5938     0.0359      98.9000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:27,059 Client1]:          9          Y                                          0.0359      98.9000\n",
      "\u001b[34m\u001b[1mappfl: ‚úÖ\u001b[0m[2025-01-06 12:05:30,008 Client1]:          9          N     2.9477     0.0046        98.6562     0.0388      98.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain general client-side configurations from the server and load them\n",
    "client_config = client_communicator.get_configuration()\n",
    "client_agent.load_config(client_config)\n",
    "\n",
    "# Obtain the initial global model from the server\n",
    "init_global_model = client_communicator.get_global_model(init_model=True)\n",
    "client_agent.load_parameters(init_global_model)\n",
    "\n",
    "# Send the number of local data to the server\n",
    "sample_size = client_agent.get_sample_size()\n",
    "client_communicator.invoke_custom_action(\n",
    "    action=\"set_sample_size\", sample_size=sample_size\n",
    ")\n",
    "\n",
    "while True:\n",
    "    client_agent.train()\n",
    "    local_model = client_agent.get_parameters()\n",
    "    if isinstance(local_model, tuple):\n",
    "        local_model, meta_data_local = local_model[0], local_model[1]\n",
    "    else:\n",
    "        meta_data_local = {}\n",
    "    new_global_model, metadata = client_communicator.update_global_model(\n",
    "        local_model, **meta_data_local\n",
    "    )\n",
    "    if metadata[\"status\"] == \"DONE\":\n",
    "        break\n",
    "    client_agent.load_parameters(new_global_model)\n",
    "client_communicator.invoke_custom_action(action=\"close_connection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
