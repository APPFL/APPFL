{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Client over Secure RPC\n",
    "\n",
    "In this notebook, we will present how to launch a gRPC client as an FL client with an authenticator. To pair with the server notebook, we consider only one client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load client configurations\n",
    "\n",
    "We load the configuration for the client from `examples/resources/configs/mnist/client_1.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id: Client1\n",
      "train_configs:\n",
      "  device: cpu\n",
      "  logging_output_dirname: ./output\n",
      "  logging_output_filename: result\n",
      "data_configs:\n",
      "  dataset_path: ./resources/dataset/mnist_dataset.py\n",
      "  dataset_name: get_mnist\n",
      "  dataset_kwargs:\n",
      "    num_clients: 2\n",
      "    client_id: 0\n",
      "    partition_strategy: class_noniid\n",
      "    visualization: true\n",
      "    output_dirname: ./output\n",
      "    output_filename: visualization.pdf\n",
      "comm_configs:\n",
      "  grpc_configs:\n",
      "    server_uri: localhost:50051\n",
      "    max_message_size: 1048576\n",
      "    use_ssl: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "client_config_file = \"../../examples/resources/configs/mnist/client_1.yaml\"\n",
    "client_config = OmegaConf.load(client_config_file)\n",
    "print(OmegaConf.to_yaml(client_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° We need to change the relative path in `data_configs.dataset_path` to point to the right file relative to this notebook.\n",
    "\n",
    "üí° We also need to change `data_configs.dataset_kwargs.num_clients` to 1 to make sure we only partition the MNIST dataset to one client split. We change `data_configs.dataset_kwargs.visualization` to False as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.data_configs.dataset_path = (\n",
    "    \"../../examples/resources/dataset/mnist_dataset.py\"\n",
    ")\n",
    "client_config.data_configs.dataset_kwargs.num_clients = num_clients\n",
    "client_config.data_configs.dataset_kwargs.visualization = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secure SSL channel and authenticator\n",
    "\n",
    "The client requires a root certificate to verify the server certificate. In this example, we provide that [root certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/root.crt), assuming that the server uses self-signed [certificate](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.crt) and [key](https://github.com/APPFL/APPFL/blob/main/src/appfl/comm/grpc/credentials/localhost.key) provided by gRPC official documentation.\n",
    "\n",
    "üí° Please check this [tutorial](https://appfl.ai/en/latest/tutorials/examples_ssl.html) for more details on how to generate SSL certificates for securing the gRPC connections in practice.\n",
    "\n",
    "To use the provided root certificate, user just to need to set the following. If the user would like to use his own root certificate, just change this to the file path to the local root certificate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_ssl = True\n",
    "client_config.comm_configs.grpc_configs.root_certificate = (\n",
    "    \"../../src/appfl/comm/grpc/credentials/root.crt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set configurations to use the naive authenticator and provide the `auth_token` agreed with the server for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_config.comm_configs.grpc_configs.use_authenticator = True\n",
    "client_config.comm_configs.grpc_configs.authenticator = \"NaiveAuthenticator\"\n",
    "client_config.comm_configs.grpc_configs.authenticator_args = {\n",
    "    \"auth_token\": \"A_SECRET_DEMO_TOKEN\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the client agent and communicator\n",
    "\n",
    "Now we are ready to create the client agent using the `client_agent` defined and modified above, as well as a `GRPCClientCommunicator` to send request to the server.\n",
    "\n",
    "‚ö†Ô∏è Please make sure that you have started the server from the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-25 21:13:12,868 INFO Client1]: Logging to ./output/result_Client1_2024-12-25-21-13-12.txt\n"
     ]
    }
   ],
   "source": [
    "from appfl.agent import ClientAgent\n",
    "from appfl.comm.grpc import GRPCClientCommunicator\n",
    "\n",
    "client_agent = ClientAgent(client_agent_config=client_config)\n",
    "client_communicator = GRPCClientCommunicator(\n",
    "    client_id=client_agent.get_id(),\n",
    "    **client_config.comm_configs.grpc_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the FL experiment\n",
    "\n",
    "Client start the FL experiment by doing the following things:\n",
    "\n",
    "- Obtain general client-side configurations from the server and load them\n",
    "- Obtain the initial global model from the server\n",
    "- *[Optional]* Send the number of local data to the server\n",
    "- Iteratively train the model and update the global model until receiving a `DONE` status flag from the server.\n",
    "\n",
    "üí° The server is also logging several information regarding the recipe of client requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-25 21:13:19,453 INFO Client1]:      Round   Pre Val?       Time Train Loss Train Accuracy   Val Loss Val Accuracy\n",
      "[2024-12-25 21:13:20,469 INFO Client1]:          0          Y                                          2.3006      15.9300\n",
      "[2024-12-25 21:13:23,361 INFO Client1]:          0          N     2.8921     0.0661        81.3125     0.1673      95.1700\n",
      "[2024-12-25 21:13:24,419 INFO Client1]:          1          Y                                          0.1673      95.1700\n",
      "[2024-12-25 21:13:27,223 INFO Client1]:          1          N     2.8028     0.0172        95.0938     0.1102      96.5900\n",
      "[2024-12-25 21:13:28,299 INFO Client1]:          2          Y                                          0.1102      96.5900\n",
      "[2024-12-25 21:13:31,202 INFO Client1]:          2          N     2.9023     0.0122        96.3438     0.0753      97.7500\n",
      "[2024-12-25 21:13:32,264 INFO Client1]:          3          Y                                          0.0753      97.7500\n",
      "[2024-12-25 21:13:35,183 INFO Client1]:          3          N     2.9181     0.0096        97.3438     0.0645      98.0800\n",
      "[2024-12-25 21:13:36,243 INFO Client1]:          4          Y                                          0.0645      98.0800\n",
      "[2024-12-25 21:13:39,150 INFO Client1]:          4          N     2.9068     0.0081        97.5156     0.0654      97.8000\n",
      "[2024-12-25 21:13:40,209 INFO Client1]:          5          Y                                          0.0654      97.8000\n",
      "[2024-12-25 21:13:43,070 INFO Client1]:          5          N     2.8605     0.0068        97.7969     0.0577      98.2700\n",
      "[2024-12-25 21:13:44,141 INFO Client1]:          6          Y                                          0.0577      98.2700\n",
      "[2024-12-25 21:13:47,009 INFO Client1]:          6          N     2.8672     0.0058        98.3594     0.0446      98.5700\n",
      "[2024-12-25 21:13:48,079 INFO Client1]:          7          Y                                          0.0446      98.5700\n",
      "[2024-12-25 21:13:50,940 INFO Client1]:          7          N     2.8604     0.0057        98.3750     0.0371      98.8900\n",
      "[2024-12-25 21:13:52,003 INFO Client1]:          8          Y                                          0.0371      98.8900\n",
      "[2024-12-25 21:13:54,920 INFO Client1]:          8          N     2.9160     0.0061        98.1875     0.0494      98.3000\n",
      "[2024-12-25 21:13:55,975 INFO Client1]:          9          Y                                          0.0494      98.3000\n",
      "[2024-12-25 21:13:58,842 INFO Client1]:          9          N     2.8663     0.0051        98.6719     0.0421      98.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain general client-side configurations from the server and load them\n",
    "client_config = client_communicator.get_configuration()\n",
    "client_agent.load_config(client_config)\n",
    "\n",
    "# Obtain the initial global model from the server\n",
    "init_global_model = client_communicator.get_global_model(init_model=True)\n",
    "client_agent.load_parameters(init_global_model)\n",
    "\n",
    "# Send the number of local data to the server\n",
    "sample_size = client_agent.get_sample_size()\n",
    "client_communicator.invoke_custom_action(\n",
    "    action=\"set_sample_size\", sample_size=sample_size\n",
    ")\n",
    "\n",
    "while True:\n",
    "    client_agent.train()\n",
    "    local_model = client_agent.get_parameters()\n",
    "    if isinstance(local_model, tuple):\n",
    "        local_model, meta_data_local = local_model[0], local_model[1]\n",
    "    else:\n",
    "        meta_data_local = {}\n",
    "    new_global_model, metadata = client_communicator.update_global_model(\n",
    "        local_model, **meta_data_local\n",
    "    )\n",
    "    if metadata[\"status\"] == \"DONE\":\n",
    "        break\n",
    "    client_agent.load_parameters(new_global_model)\n",
    "client_communicator.invoke_custom_action(action=\"close_connection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
